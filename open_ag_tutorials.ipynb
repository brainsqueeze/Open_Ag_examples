{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn API examples\n",
    "========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to need to read in some data.  In this case we can use a built-in\n",
    "dataset that is packaged with scikit-learn.  We split the dataset into a training \n",
    "set and a test set.\n",
    "\n",
    "Typically the test set is held out until after the model is fully trained, and a\n",
    "separate validation set is pulled out from the training set to evaluate performance\n",
    "at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print newsgroups_train.keys(), '\\n'\n",
    "\n",
    "print newsgroups_train['data'][:2], '\\n'\n",
    "print zip(newsgroups_train['target'][:2], newsgroups_train['target_names'][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to transform text data into a mathematical structure to feed into our\n",
    "chosen machine learning algorithm.  TF-IDF transformations count word/phrase frequencies\n",
    "and punish very frequent, non-descriptive words such as 'the', 'as', 'and' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_train = vectorizer.fit_transform(newsgroups_train['data'])  # training data matrix (sparse)\n",
    "y_train = np.array(newsgroups_train['target'])  # target values, want to learn to associate data with these values\n",
    "\n",
    "print x_train\n",
    "print y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering and Intrinsic Data Structures\n",
    "========================================\n",
    "\n",
    "Often when choosing a particular model it is necessary to understand your data and how it\n",
    "is structured.  Using dimensionality reduction techniques as well as some clustering techniques\n",
    "we can extract hidden structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "svd = TruncatedSVD()\n",
    "tsne = TSNE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_red = svd.fit_transform(x_train[:5000])\n",
    "x_red = tsne.fit_transform(x_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_embedding(var_embed, labels):\n",
    "    c_dict = {idx + 1: val for idx, val in enumerate(newsgroups_train['target_names'])}\n",
    "\n",
    "    var_x, var_y = var_embed[:, 0], var_embed[:, 1]\n",
    "    var_x = (var_x - var_x.min()) / (var_x.max() - var_x.min())\n",
    "    var_y = (var_y - var_y.min()) / (var_y.max() - var_y.min())\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    norm = plt.Normalize()\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(c_dict)))\n",
    "    \n",
    "    for k in c_dict:\n",
    "        ax.scatter(var_x[labels == k], var_y[labels == k], c=colors[k-1], edgecolors=None, alpha=0.7, label=c_dict[k])\n",
    "    plt.legend(loc=3)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_embedding(x_red, y_train[:5000])\n",
    "print np.asarray(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is somewhat separated by class, and similar class types tend to fall into\n",
    "the same large scale clusters.  Since the clusters aren't linearly separated we will \n",
    "choose a model that can handle non-linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = vectorizer.transform(newsgroups_test['data'])\n",
    "y_test = np.array(newsgroups_test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Let's examine how the model performed.  First we will look at some specific \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names = {idx: val for idx, val in enumerate(newsgroups_train['target_names'])}\n",
    "# print predictions[:10], [names[p] for p in predictions[:10]]\n",
    "\n",
    "for idx, text in enumerate(newsgroups_test['data'][:10]):\n",
    "    print text[:500]\n",
    "    print 'Predicted: ', names[predictions[idx]], '; Expected: ', names[y_test[idx]]\n",
    "    print '========================='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "precision, recall, f_score, support = score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(precision)):\n",
    "    print \"Label: {0} | Precision: {1}, Recall: {2}, F1: {3}\".format(newsgroups_train['target_names'][i], \n",
    "                                                                     precision[i], \n",
    "                                                                     recall[i], \n",
    "                                                                     f_score[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
